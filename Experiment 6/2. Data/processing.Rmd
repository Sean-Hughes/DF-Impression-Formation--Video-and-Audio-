---
title: "Experiment 4"
subtitle: "Data processing"
author: "Sean Hughes"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes 
    toc_float: yes
---

```{r include=FALSE}
knitr::opts_chunk$set(message=FALSE,
                      warning=FALSE)
```

# Functions and Dependencies

```{r}

library(tidyverse)
library(readxl)
library(ggthemes)
library(knitr)
library(kableExtra)
library(IATscores)
library(pacman)
library(RSQLite)
library(jsonlite)
library(janitor)
library(Hmisc)
library(ggplot2)
library(haven)
library(IATscores)
library(xlsx)

# Used to reduce unique ids to a smaller number
count_unique <- function(x) {
  return(length(unique(x)))
}
information_preserved <- function(x, length) {
  return(
    count_unique(str_sub(x, end=i)) ==
      count_unique(x)
  )
}

# used to extract the JSON data
parseJSON <- function(input) {
  return(input %>%
           fromJSON(flatten=T) %>% {
             # Coerce lists
             if (class(.) == 'list') {
               discard(., is.null) %>%
                 as_tibble()
             } else {
               .
             } } %>%
           # Sanitize names
           janitor::clean_names() %>%
           # Use only strings for now, and re-encode types later
           mutate_all(as.character))
}


```

# Extract data files from zip file 

```{r}

# Github does not play nicely with files > 100mb. So I compressed the data files so they could be uploaded. You need to uncompress them to run the code chunks below

genuine_data <- c("raw/Experiment_4_Genuine_data.zip")

unzip(genuine_data, exdir = "raw")

deepfaked_data <- c("raw/Experiment_4_DF_data.zip")

unzip(deepfaked_data, exdir = "raw")

rm(genuine_data, deepfaked_data)

```


# Genuine audio: Connect to the SQL Database

```{r}

# 'Connect' to database
connection <- dbConnect(
  drv=RSQLite::SQLite(),
  dbname= "raw/Experiment_4_Genuine_data.sqlite")

# Extract main table
database_genuine_audio <- dbGetQuery(
  conn=connection,
  statement='SELECT * FROM labjs')

# Close connection
dbDisconnect(
  conn=connection)

# Discard connection
rm(connection)

```

## Extract Metadata

```{r}

database_genuine_audio_meta_data <- map_dfr(database_genuine_audio$metadata, fromJSON) %>%
  dplyr::rename(observation = id)

database_genuine_audio <- database_genuine_audio %>%
  bind_cols(database_genuine_audio_meta_data) %>%
  
  # Remove metadata column
  select(-metadata)

# Remove temporary data frame
rm(database_genuine_audio_meta_data)

```

## Shorten random id for each participant

```{r}

# Reduce the length of the random id variable to five characters (this is a sufficient length to identify each unique participant)

for (i in 5:36) {
  if (
    information_preserved(database_genuine_audio$session, i) &&
    information_preserved(database_genuine_audio$observation, i)
  ) {
    break()
  }
}
database_genuine_audio <- database_genuine_audio %>%
  dplyr::mutate(
    session=str_sub(session, end=i),
    observation=str_sub(observation, end=i))

rm(i, count_unique, information_preserved)

```

## Extract full data from database

```{r}

database_genuine_audio_full <- database_genuine_audio %>%
  dplyr::filter(payload == 'full') 

if (nrow(database_genuine_audio_full) > 0) {
  database_genuine_audio_full %>%
    group_by(observation, id) %>%
    do(
      { map_dfr(.$data, parseJSON) } %>%
        bind_rows()
    ) %>%
    ungroup() %>%
    select(-id) -> database_genuine_audio_full
}

```

## Extract incremental data from database

```{r}

database_genuine_audio %>%
  dplyr::filter(payload %in% c('incremental', 'latest')) %>%
  group_by(observation, id) %>%
  do(
    { map_dfr(.$data, parseJSON) } %>%
      bind_rows()
  ) %>%
  ungroup() %>%
  select(-id) -> database_genuine_audio_incremental

gc()

```

## Merge full and incremental datasets

```{r}
##Merge data sets

#For analysis, we'll use the full data sets where available, and incremental data when it is the the only information we have for a user.

raw_data_genuine_audio <- database_genuine_audio_full %>%
  bind_rows(
    database_genuine_audio_incremental %>% 
      filter(!(observation %in% database_genuine_audio_full$observation))) %>%
  type_convert()

gc()

# rename the observation column to subject

raw_data_genuine_audio <- raw_data_genuine_audio %>% 
  rename(subject = observation)

```

## Postprocessing

```{r}
# Ensures that all cells contain the same value even if only a subset of those cells is currently filled

raw_data_genuine_audio %>%
  group_by(subject) %>%
  fill(matches('code'), .direction='down') %>%
  fill(matches('code'), .direction='up') %>%
  ungroup() -> raw_data_genuine_audio

rm(database_genuine_audio, database_genuine_audio_full, database_genuine_audio_incremental)

# Create  a backup of the data while I am writing the script so I don't have to work with the database which takes a bunch of time

Raw_Data_genuine <- raw_data_genuine_audio 
```


#  Deepfaked audio: Connect to the SQL Database

```{r}

# 'Connect' to database
connection <- dbConnect(
  drv=RSQLite::SQLite(),
  dbname= "raw/Experiment_4_DF_data.sqlite")

# Extract main table
database_deepfaked_audio <- dbGetQuery(
  conn=connection,
  statement='SELECT * FROM labjs')

# Close connection
dbDisconnect(
  conn=connection)

# Discard connection
rm(connection)

```

## Extract Metadata

```{r}

database_deepfaked_audio_meta_data <- map_dfr(database_deepfaked_audio$metadata, fromJSON) %>%
  dplyr::rename(observation = id)

database_deepfaked_audio <- database_deepfaked_audio %>%
  bind_cols(database_deepfaked_audio_meta_data) %>%
  
  # Remove metadata column
  select(-metadata)

# Remove temporary data frame
rm(database_deepfaked_audio_meta_data)

```

## Shorten random id for each participant

```{r}

# Reduce the length of the random id variable to five characters (this is a sufficient length to identify each unique participant)

for (i in 5:36) {
  if (
    information_preserved(database_deepfaked_audio$session, i) &&
    information_preserved(database_deepfaked_audio$observation, i)
  ) {
    break()
  }
}
database_deepfaked_audio <- database_deepfaked_audio %>%
  dplyr::mutate(
    session=str_sub(session, end=i),
    observation=str_sub(observation, end=i))

rm(i, count_unique, information_preserved)

```

## Extract full data from database

```{r}

database_deepfaked_audio_full <- database_deepfaked_audio %>%
  dplyr::filter(payload == 'full') 

if (nrow(database_deepfaked_audio_full) > 0) {
  database_deepfaked_audio_full %>%
    group_by(observation, id) %>%
    do(
      { map_dfr(.$data, parseJSON) } %>%
        bind_rows()
    ) %>%
    ungroup() %>%
    select(-id) -> database_deepfaked_audio_full
}

```

## Extract incremental data from database

```{r}

database_deepfaked_audio %>%
  dplyr::filter(payload %in% c('incremental', 'latest')) %>%
  group_by(observation, id) %>%
  do(
    { map_dfr(.$data, parseJSON) } %>%
      bind_rows()
  ) %>%
  ungroup() %>%
  select(-id) -> database_deepfaked_audio_incremental

gc()

```

## Merge full and incremental datasets

```{r}
##Merge data sets

#For analysis, we'll use the full data sets where available, and incremental data when it is the the only information we have for a user.

raw_data_deepfaked_audio <- database_deepfaked_audio_full %>%
  bind_rows(
    database_deepfaked_audio_incremental %>% 
      filter(!(observation %in% database_deepfaked_audio_full$observation))) %>%
  type_convert()

gc()

# rename the observation column to subject

raw_data_deepfaked_audio <- raw_data_deepfaked_audio %>% 
  rename(subject = observation)

```

## Postprocessing

```{r}
# Ensures that all cells contain the same value even if only a subset of those cells is currently filled

raw_data_deepfaked_audio %>%
  group_by(subject) %>%
  fill(matches('code'), .direction='down') %>%
  fill(matches('code'), .direction='up') %>%
  ungroup() -> raw_data_deepfaked_audio

rm(database_deepfaked_audio, database_deepfaked_audio_full, database_deepfaked_audio_incremental)

# Create  a backup of the data while I am writing the script so I don't have to work with the database which takes a bunch of time

Raw_Data_deepfake <- raw_data_deepfaked_audio 
```

# Combine  Genuine and Deepfaked Data 
```{r}

raw_data_genuine_audio <- raw_data_genuine_audio %>% 
  mutate(audio_type = "genuine audio") 

raw_data_deepfaked_audio <- raw_data_deepfaked_audio %>% 
  mutate(audio_type = "deepfake audio")

raw_data_combined <- raw_data_genuine_audio %>% 
  full_join(raw_data_deepfaked_audio)

```

# Demographics and Method Factors 

```{r}

current_experiment_number <- 4

# Select out the demographic and method factor information

data_demographics_and_methods <- raw_data_combined %>% 
  select(subject,
         audio_type,
         prolific_id, 
         age, 
         gender, 
         condition, 
         name) %>%
  
  group_by(subject) %>%
  
  # Remove na values (note: this does not exclude participants)
  
  summarise_all(funs(first(na.omit(.)))) %>% 
  
   mutate(condition_number = case_when(grepl("C1", condition) ~ 1, 
                                              grepl("C2", condition) ~ 2, 
                                              grepl("C3", condition) ~ 3, 
                                              grepl("C4", condition) ~ 4)) %>%
  
  mutate(IAT_block_order = case_when(grepl("Incon B", condition) ~ "learning inconsistent block First", 
                                     grepl("Con B", condition) ~ "learning consistent block First")) %>% 
  
  mutate(experiment_condition = case_when(grepl("Positive_Audio", condition) ~ "positive audio", 
                                          grepl("Negative_Audio", condition) ~ "negative audio")) %>% 
  
  mutate(task_order = case_when(grepl("IAT_First", condition) ~ "iat first", 
                                grepl("SR_First", condition) ~ "ratings first"))

```

# Self-Reported Ratings 

```{r}

# select out the self-reported ratings and the participant id (subject)

data_self_reports <- raw_data_combined %>% 
  
  select(subject, 
         pos_neg, 
         good_bad, 
         like_dislike) %>% 
  
  group_by(subject) %>%
  
  summarise_all(funs(first(na.omit(.)))) %>% 
  # create an average rating score 
  mutate(self_reported_rating = (pos_neg + good_bad + like_dislike)/3) %>% 
  mutate_if(is.numeric, round, digits = 2) 

```

# Exploratory Questions


```{r}

# Select and retain only the exploratory questions and participant id

data_exploratory_questions <- raw_data_combined %>% 
  
  select(subject, 
         memory_of_audio_content, 
         diagnosticity_question, 
         demand, 
         reactance, 
         hypothesis_awareness, 
         influence_awareness, 
         issues_with_study,
         deepfake_check) %>% 
  
  group_by(subject) %>%
  
  summarise_all(funs(first(na.omit(.))))

```

# IAT

## Tidying

```{r}

data_iat_input <- raw_data_combined %>%
  
  # Select and retain IAT related variables
  
  select(subject, 
         name, 
         corr,
         sender, 
         sender_id, 
         correct, 
         duration) %>%
  
  # Select out only the data where the stimulus was shown
  
  filter(sender == 'Stimulus') %>% 
  
  # Create a block and Trial column. Do so by renaming values from the 'sender_id' column to terms that the IAT script will work with (e.g., block 1,2,3,4,5,6,7)
  
  separate(sender_id, into = c("temp_1", "temp_2", "temp_3", "block", "trial"), sep = "_") %>%
  
  select(-temp_1, -temp_2, -temp_3) %>% 
  
  # Recode trial numbers so that they begin at 1 and run to 16 or 32
  
  mutate(block = as.numeric(block),
         trial = as.numeric(trial) + 1) %>%
  rename(trial_number = trial) %>%
  
  # Recode the TRUE/FALSE values from the correct column to 1,0 
  
  mutate(Correct = case_when(grepl("TRUE", correct) ~ 1,
                             grepl("FALSE", correct) ~ 0)) %>%
  
  # Bring in the correct (i.e., Revised) Experimental Condition information from the Demographics File
  
  full_join(data_demographics_and_methods, by = 'subject') %>%
  
  # Recode block
  # For participants in Conditions 1-2 the 'sender_id variable' corresponds to the following block order (this can be seen by inspecting the name and corr variables in the raw data):
  
  # _3_0_0   = block 1 (Bob Chris)
  # _5_0_0   = block 2 (Bad Good)
  # _7_0_0   = block 3 (Bob Bad Chris Good)
  # _9_0_0   = block 4 (Bob Bad Chris Good)
  # _11_0_0  = block 5 (Chris Bob)
  # _13_0_0  = block 6 (Chris Bad Bob Good)
  # _15_0_0  = block 7 (Chris Bad Bob Good)

# For participants in Conditions 3-4 the 'sender_id variable' corresponds to the following block order:

# _3_0_0   = block 5 (Chris Bob)
# _5_0_0   = block 2 (Bad Good)
# _7_0_0   = block 6 (Chris Bad Bob Good)
# _9_0_0   = block 7 (Chris Bad Bob Good)
# _11_0_0  = block 1 (Bob Chris)
# _13_0_0  = block 3 (Bob Bad Chris Good)
# _15_0_0  = block 4 (Bob Bad Chris Good)

# Create a new variable (Revised block) and update the block numbering so that it is correct: 

mutate(revised_block = ifelse(condition_number %in% c(1, 2), 
                              case_when(block == 3 ~ 1,
                                        block == 5 ~ 2,
                                        block == 7 ~ 3,
                                        block == 9 ~ 4,
                                        block == 11 ~ 5,
                                        block == 13 ~ 6,
                                        block == 15 ~ 7), 
                              ifelse(condition_number %in% c(3, 4), 
                                     case_when(block == 3 ~ 5,
                                               block == 5 ~ 2,
                                               block == 7 ~ 6,
                                               block == 9 ~ 7,
                                               block == 11 ~ 1,
                                               block == 13 ~ 3,
                                               block == 15 ~ 4),NA))) %>%
#Select IAT related data 

select(subject, 
       condition,
       condition_number,
       name = name.x,
       corr,
       trial_number, 
       block, 
       revised_block, 
       correct, 
       duration, 
       IAT_block_order)

# rename columns that IATscores package will use later on
  
data_iat_input <- data_iat_input %>%
  mutate(experiment = current_experiment_number) %>%
  select(subject, 
         trial_number, 
         block = revised_block, 
         correct, 
         latency = duration, 
         IAT_block_order,
         condition,
         condition_number)

# only retain the critical practice and test blocks (i.e., block_number = 3, 4, 6, 7)

data_iat_cleaned <- data_iat_input %>%
  filter(block %in% c(3, 4, 6, 7)) %>%


  # Create a new variable called Block_Type that indicates if a given block is a compatible or incompatible test block and if it is the first or second such block
  
  # Participants in Condition 1, 2 received a positive audio. Therefore blocks 3,4 are consistent with the audio and blocks 6,7 are inconsistent with the audio.
  
  # Participants in Condition 3, 4 received a negative audio. Therefore blocks 3,4 are inconsistent with the audio and 6,7 are consistent with the audio.  
  
  mutate(block_type = ifelse(condition_number %in% c(1, 2), 
                             case_when(block == 3 ~ "compatibletest1",
                                       block == 4 ~ "compatibletest2",
                                       block == 6 ~ "incompatibletest1",
                                       block == 7 ~ "incompatibletest2"), 
                             ifelse(condition_number %in% c(3, 4), 
                                    case_when(block == 3 ~ "incompatibletest1",
                                              block == 4 ~ "incompatibletest2",
                                              block == 6 ~ "compatibletest1",
                                              block == 7 ~ "compatibletest2"),NA)))

```


## Completeness

```{r}

data_iat_completeness <- data_iat_cleaned %>%
  group_by(subject) %>%
  summarise(n = n()) %>%
  mutate(complete_iat_data = case_when(n == 128 ~ "complete", 
                                       n > 128 ~ "excess", 
                                       n < 128 ~"partial")) %>%
  ungroup() %>%
  select(-n)

data_iat_completeness %>%
  distinct(subject, .keep_all = TRUE) %>%
  count(complete_iat_data) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```


## Performance

```{r}

# exclude if total error rate > 30% 
data_iat_accuracy_overall <- data_iat_cleaned %>% 
  group_by(subject) %>% 
  summarise(iat_accuracy_overall = sum(correct)/n()) %>%
  ungroup() %>%
  mutate(passed_iat_accuracy_overall = ifelse(iat_accuracy_overall >= .70, TRUE, FALSE)) %>%
  select(subject, passed_iat_accuracy_overall)

# exclude if error rate on any one block > 40% 
data_iat_accuracy_by_block <- data_iat_cleaned %>% 
  group_by(subject, block) %>% 
  summarise(iat_accuracy_by_block = sum(correct)/n()) %>%
  ungroup() %>%
  mutate(passed_iat_accuracy_by_block = ifelse(iat_accuracy_by_block >= .60, TRUE, FALSE)) %>%
  group_by(subject) %>%
  summarise(passed_iat_accuracy_by_block = as.logical(min(passed_iat_accuracy_by_block))) %>%
  ungroup()

data_iat_fast_responding <- data_iat_cleaned %>% 
  mutate(fast_response = ifelse(latency < 300, 1, 0)) %>%
  group_by(subject) %>% 
  summarise(iat_percent_fast_responses = sum(fast_response)/n()) %>%
  ungroup() %>%
  mutate(passed_iat_percent_fast_responses = ifelse(iat_percent_fast_responses <= .10, TRUE, FALSE)) %>%
  select(subject, passed_iat_percent_fast_responses)

data_iat_performance <- data_iat_accuracy_overall %>%
  full_join(data_iat_accuracy_by_block, by = "subject") %>%
  full_join(data_iat_fast_responding, by = "subject") %>%
  rowwise() %>%
  mutate(passed_iat_performance = as.logical(min(c(passed_iat_accuracy_overall, 
                                                   passed_iat_accuracy_by_block,   
                                                   passed_iat_percent_fast_responses), na.rm = TRUE))) %>%
  ungroup() %>%
  select(subject, passed_iat_performance)

rm(data_iat_accuracy_overall, data_iat_accuracy_by_block, data_iat_fast_responding)

```

## D2 scoring

```{r}

data_iat_D2_scores <- data_iat_cleaned %>%
  # rename and recode to create the input format that the IATscores package requires
  mutate(praccrit = ifelse(block_type == "incompatibletest1" | block_type == "compatibletest1", 
                           "prac", "crit"),
         blockcode = ifelse(block_type == "incompatibletest1" | block_type == "incompatibletest2",
                            "incompatible_block", "compatible_block")) %>%
  select(subject, subject, block, correct, latency, praccrit,  trial_number, block_type) %>%
  mutate(blockcode = ifelse(block %in% c(3, 4), "pair1", 
                            ifelse(block %in% c(6, 7), "pair2", NA)),
         praccrit = ifelse(block %in% c(3, 6), "prac", 
                           ifelse(block %in% c(4, 7), "crit", NA)))  %>%
  filter(!is.na(blockcode)) %>%
  # calculate D2 scores
  # parameters are identical to those the package lists in the D2 wrapper function
  IATscores::RobustScores(IATdata = .,
                          P1 = "fxtrim",  # Trim values < 400ms
                          P2 = "ignore",  # do not trim errors
                          P3 = "dscore",  # calculate d2 scores
                          P4 = "dist",    # distinguish between the prac and test blocks
                          verbose = FALSE,
                          autoremove = FALSE) %>%
  rename(IAT_D2_score = p2112) 

```
## Join the Various Files Together

```{r}

# Join all the files together for analyses

data_processed <- data_demographics_and_methods %>% 
  full_join(data_self_reports, by ='subject') %>%
  full_join(data_exploratory_questions, by ='subject') %>%
  full_join(data_iat_D2_scores, by='subject') %>% 
  full_join(data_iat_completeness, by='subject') %>% 
  full_join(data_iat_performance, by='subject') 

# Add in numeric ids for participants 

unique_ids <- data_processed %>% 
  distinct(subject) %>%
  rownames_to_column(var = "numeric_id") %>%
  mutate(numeric_id = as.numeric(as.character(numeric_id))) 

data_processed <- data_processed %>% 
  full_join(unique_ids, by = "subject") 

# Order the columns for subsequent analyses

data_processed <- data_processed %>% 
  mutate(experiment = current_experiment_number) %>%
  select(numeric_id, 
         #subject, 
         experiment,
         gender, 
         age, 
         condition,
         experiment_condition, 
         audio_type,
         task_order, 
         IAT_block_order,
         complete_iat_data,
         passed_iat_performance,
         pos_neg, 
         good_bad,
         like_dislike, 
         self_reported_rating,
         IAT_D2_score,
         memory_of_audio_content, 
         diagnosticity_question, 
         demand, 
         reactance, 
         hypothesis_awareness, 
         influence_awareness, 
         issues_with_study,
         deepfake_check)

```

## Scoring People as Aware or Non-Aware of the Deepfake Manipulation

```{r}
# We used an open ended questions to gauge if people were aware that the deepfaked audio was deepfaked. In order to score this as 1 (aware) or 0 (unaware) we exported the values to an excel sheet, manually scored them, and them imported the values back into R for later analysis.

# Select out the deepfake check info and participant id values. Write these values to an excel sheet
data_deepfake_check <- data_processed %>% 
  select(numeric_id, deepfake_check)

write.xlsx(data_deepfake_check, "processed/data_deepfake_check.xlsx")

# Import the manually scored values back into R for later analysis

data_deepfake_check <- read_excel("processed/data_deepfake_check_coded.xlsx") %>%
  select(numeric_id, deepfake_awareness)

# Add the information to the processed data file
data_processed <- data_processed %>% 
  full_join(data_deepfake_check, by = "numeric_id")


```

# Combine and write to disk

```{r}

# Ensures that the processed data folder exists
dir.create("processed")

# write to disk
write_csv(data_processed, "processed/data_processed.csv")

data <- read_csv("processed/data_processed.csv")

```


